{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "9WpL-9rsqXXS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Drive Authentication"
      ],
      "metadata": {
        "id": "bb8PFrgbqhC_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxIUWrRsqVZo"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "metadata": {
        "id": "zxtNlcxOqfue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS + MRI Loading"
      ],
      "metadata": {
        "id": "2nNUdFAIqmbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "\n",
        "# Note all file paths had to be removed in order to mantain privacy of patient data in accordance to the National Alzheimer's Coordinating Center licence agreement\n",
        "\n",
        "\n",
        "uds_file_id = '[GoogleDriveFileId]'\n",
        "downloaded = drive.CreateFile({'id': uds_file_id})\n",
        "downloaded.GetContentFile(\"[GoogleDriveFileName].csv\")\n",
        "\n",
        "mri_scan_file_id = 'GoogleDriveFileId'\n",
        "downloaded = drive.CreateFile({'id': mri_scan_file_id})\n",
        "downloaded.GetContentFile(\"GoogleDriveFileName.csv\")"
      ],
      "metadata": {
        "id": "s6wKWSdhqoTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data into Datafarmes\n",
        "\n",
        "udslong=pd.read_csv('investigator_nacc65.csv',index_col=0,header=0)\n",
        "mriscanlong=pd.read_csv('investigator_scan_mrisbm_nacc65.csv',index_col=0,header=0)"
      ],
      "metadata": {
        "id": "jEtnS8qfrW32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter by NACCALZP to get all those afflicted with alzheimers or cognitively healthy\n",
        "\n",
        "udslong = udslong[udslong['NACCALZP'].isin([1,2,8])].copy()\n",
        "udslong"
      ],
      "metadata": {
        "id": "he4CXy0ZrpCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the overlapping index values\n",
        "overlapping_indices = udslong.index.intersection(mriscanlong.index)\n",
        "\n",
        "# Print the number of overlapping index values\n",
        "print('Number of overlapping index values (NACCID):', len(overlapping_indices))\n",
        "\n",
        "# Output: 1237 Unique Patient IDs"
      ],
      "metadata": {
        "id": "PqVZVwrOrwRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the overlapping index values\n",
        "overlapping_indices = udslong.index.intersection(mriscanlong.index)\n",
        "\n",
        "# Filter the udslong DataFrame to include only the overlapping indices\n",
        "overlapping_udslong = udslong.loc[overlapping_indices]\n",
        "\n",
        "# Calculate the distribution of NACCUDSD values\n",
        "naccudsd_distribution = overlapping_udslong['NACCUDSD'].value_counts(normalize=True) * 100\n",
        "\n",
        "# Print the distribution\n",
        "print(naccudsd_distribution)\n",
        "\n",
        "# Check percentage of remaining AD patients and controls"
      ],
      "metadata": {
        "id": "gSIl_8Lhr3Fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the overlapping index values\n",
        "overlapping_indices = udslong.index.intersection(mriscanlong.index)\n",
        "\n",
        "# Filter both DataFrames to only include rows with overlapping NACCIDs\n",
        "udslong_filtered = udslong.loc[overlapping_indices]\n",
        "mriscanlong_filtered = mriscanlong.loc[overlapping_indices]\n",
        "\n",
        "# Print the shapes of the filtered DataFrames to verify\n",
        "print('Shape of filtered UDS DataFrame:', udslong_filtered.shape)\n",
        "print('Shape of filtered MRI DataFrame:', mriscanlong_filtered.shape)"
      ],
      "metadata": {
        "id": "TbmIyWrtsMBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter both DataFrames to include only the first instance of each NACCID\n",
        "udslong_first_instance = udslong_filtered[~udslong_filtered.index.duplicated(keep='first')]\n",
        "mriscanlong_first_instance = mriscanlong_filtered[~mriscanlong_filtered.index.duplicated(keep='first')]\n",
        "\n",
        "# Print the shapes of the DataFrames with only the first instance of each NACCID\n",
        "print('Shape of UDS DataFrame with first instance of each NACCID:', udslong_first_instance.shape)\n",
        "print('Shape of MRI DataFrame with first instance of each NACCID:', mriscanlong_first_instance.shape)"
      ],
      "metadata": {
        "id": "C6IgsxMBr_zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS Clean"
      ],
      "metadata": {
        "id": "-U_Y6JulskZ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropping Columns"
      ],
      "metadata": {
        "id": "2YO1t4RTuA-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the feature groups\n",
        "input_demo_feats = ['SEX', 'HISPANIC', 'HISPOR', 'RACE', 'RACEX', 'PRIMLANG', 'EDUC', 'MARISTAT', 'NACCLIVS', 'INDEPEND', 'RESIDENC', 'NACCNIHR', 'NACCAGE']\n",
        "input_fam_hist_feats = ['NACCFAM', 'NACCMOM', 'NACCDAD', 'NACCAM', 'NACCAMX', 'NACCAMS', 'NACCAMSX', 'NACCFM', 'NACCFMX', 'NACCFMS', 'NACCFMSX', 'NACCOM', 'NACCOMX', 'NACCOMS', 'NACCOMSX', 'NACCFADM', 'NACCFFTD']\n",
        "input_patient_hist_feats = ['ANYMEDS', 'TOBAC30', 'TOBAC100', 'SMOKYRS', 'PACKSPER', 'QUITSMOK', 'CVHATT', 'CVAFIB', 'CVANGIO', 'CVBYPASS', 'CVPACDEF', 'CVPACE', 'CVCHF', 'CVOTHR', 'CBSTROKE', 'NACCSTYR', 'CBTIA', 'NACCTIYR', 'SEIZURES', 'NACCTBI', 'TBI', 'TBIBRIEF', 'TRAUMBRF', 'TBIEXTEN', 'TRAUMEXT', 'TBIWOLOS', 'TRAUMCHR', 'TBIYEAR', 'NCOTHR', 'DIABETES', 'DIABTYPE', 'HYPERTEN', 'HYPERCHO', 'B12DEF', 'THYROID', 'ARTHRIT', 'ARTHTYPE', 'ARTHTYPX', 'ARTHUPEX', 'ARTHLOEX', 'ARTHSPIN', 'ARTHUNK', 'INCONTU', 'INCONTF', 'APNEA', 'RBD', 'INSOMN', 'OTHSLEEP', 'OTHSLEEX', 'ALCOHOL', 'ABUSOTHR', 'ABUSX', 'PTSD', 'BIPOLAR', 'SCHIZ', 'DEP2YRS', 'DEPOTHR', 'ANXIETY', 'OCD', 'NPSYDEV', 'PSYCDIS', 'PSYCDISX', 'NACCAAAS', 'NACCAANX', 'NACCAC', 'NACCACEI', 'NACCADEP', 'NACCAHTN', 'NACCAMD', 'NACCANGI', 'NACCAPSY', 'NACCBETA', 'NACCCCBS', 'NACCDBMD', 'NACCDIUR', 'NACCEMD', 'NACCEPMD', 'NACCHTNC', 'NACCLIPL', 'NACCNSD', 'NACCPDMD', 'NACCVASD']\n",
        "input_physical_exam_feats = ['HEIGHT', 'WEIGHT', 'BPSYS', 'BPDIAS', 'HRATE', 'VISION', 'VISCORR', 'VISWCORR', 'HEARING', 'HEARAID', 'HEARWAID', 'NACCBMI', 'FOCLSYM', 'FOCLSIGN', 'NACCNREX', 'NORMEXAM']\n",
        "input_npi_feats = ['NPIQINF', 'NPIQINFX', 'DEL', 'DELSEV', 'HALL', 'HALLSEV', 'AGIT', 'AGITSEV', 'DEPD', 'DEPDSEV', 'ANX', 'ANXSEV', 'ELAT', 'ELATSEV', 'APA', 'APASEV', 'DISN', 'DISNSEV', 'IRR', 'IRRSEV', 'MOT', 'MOTSEV', 'NITE', 'NITESEV', 'APP', 'APPSEV']\n",
        "input_gds_feats = ['NOGDS', 'SATIS', 'DROPACT', 'EMPTY', 'BORED', 'SPIRITS', 'AFRAID', 'HAPPY', 'HELPLESS', 'STAYHOME', 'MEMPROB', 'WONDRFUL', 'WRTHLESS', 'ENERGY', 'HOPELESS', 'BETTER', 'NACCGDS']\n",
        "input_faq_feats = ['BILLS', 'TAXES', 'SHOPPING', 'GAMES', 'STOVE', 'MEALPREP', 'EVENTS', 'PAYATTN', 'REMDATES', 'TRAVEL', 'DECSUB']\n",
        "input_np_feats = ['MMSEORDA', 'MMSEORLO', 'PENTAGON', 'NACCMMSE', 'LOGIMEM', 'MEMUNITS', 'MEMTIME', 'DIGIF', 'DIGIFLEN', 'DIGIB', 'DIGIBLEN', 'ANIMALS', 'VEG', 'TRAILA', 'TRAILARR', 'TRAILALI', 'TRAILB', 'TRAILBRR', 'TRAILBLI', 'BOSTON', 'MOCATOTS']\n",
        "input_apoe_feats = ['NACCAPOE']\n",
        "input_uds_feats = ['NACCUDSD']\n",
        "input_cdr_feats = ['MEMORY', 'ORIENT', 'JUDGMENT', 'COMMUN', 'HOMEHOBB', 'PERSCARE', 'CDRSUM', 'CDRGLOB']\n",
        "\n",
        "all_feats = input_demo_feats + input_fam_hist_feats + input_patient_hist_feats + input_physical_exam_feats + input_npi_feats + input_gds_feats + input_faq_feats + input_np_feats + input_apoe_feats + input_uds_feats + input_cdr_feats\n",
        "\n",
        "# Filter the udslong_first_instance dataset to keep only the specified columns\n",
        "udslong_filtered = udslong_first_instance[all_feats]\n",
        "\n",
        "# Save the new dataset to a CSV file (optional)\n",
        "udslong_filtered.to_csv('filtered_udslong.csv', index=True)\n",
        "\n",
        "# Display the first few rows of the new dataset to verify\n",
        "print(udslong_filtered)"
      ],
      "metadata": {
        "id": "D3riuJOVtF__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Drop the specified columns\n",
        "columns_to_drop = [\"NACCSTYR\", \"NACCTIYR\", \"TBIYEAR\"] # 90% Missing Information\n",
        "udslong_filtered = udslong_filtered.drop(columns=columns_to_drop)\n",
        "\n",
        "# Print the names of the columns that were dropped\n",
        "print(\"\\nColumns dropped:\")\n",
        "print(columns_to_drop)\n",
        "\n",
        "# Display the first few rows of the new dataset to verify\n",
        "print(\"\\nFirst few rows of the dataset after dropping columns:\")\n",
        "print(udslong_filtered.head())"
      ],
      "metadata": {
        "id": "2quGMr0es0lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# -4 = NA Value in NACC Data\n",
        "\n",
        "# List of columns to analyze for -4 values\n",
        "columns_with_neg4 = udslong_filtered.columns[(udslong_filtered == -4).any()]\n",
        "\n",
        "# Calculate the total number of rows\n",
        "total_rows = udslong_filtered.shape[0]\n",
        "\n",
        "# Count the number of -4 values in each column\n",
        "neg4_counts = (udslong_filtered[columns_with_neg4] == -4).sum()\n",
        "\n",
        "# Calculate the percentage of -4 values in each column\n",
        "neg4_percentages = (neg4_counts / total_rows) * 100\n",
        "\n",
        "# Print the percentages\n",
        "print(\"Percentage of -4 values in each feature:\")\n",
        "print(neg4_percentages)\n",
        "\n",
        "# Return the result as a DataFrame for better visualization\n",
        "neg4_percentages_df = neg4_percentages.reset_index()\n",
        "neg4_percentages_df.columns = ['Feature', 'Percentage of -4s']\n",
        "\n",
        "# Display the DataFrame\n",
        "neg4_percentages_df"
      ],
      "metadata": {
        "id": "6qwd3MtVtQGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of columns to analyze for -4 values\n",
        "columns_with_neg4 = udslong_filtered.columns[(udslong_filtered == -4).any()]\n",
        "\n",
        "# Calculate the total number of rows\n",
        "total_rows = udslong_filtered.shape[0]\n",
        "\n",
        "# Count the number of -4 values in each column\n",
        "neg4_counts = (udslong_filtered[columns_with_neg4] == -4).sum()\n",
        "\n",
        "# Calculate the percentage of -4 values in each column\n",
        "neg4_percentages = (neg4_counts / total_rows) * 100\n",
        "\n",
        "# Identify columns with greater than 50% -4 values\n",
        "columns_greater_than_50_percent = neg4_percentages[neg4_percentages > 50]\n",
        "\n",
        "# Print the number of columns and the column names with greater than 50% -4 values\n",
        "print(f\"Number of columns with greater than 50% -4 values: {len(columns_greater_than_50_percent)}\")\n",
        "print(\"Columns with greater than 50% -4 values:\")\n",
        "print(columns_greater_than_50_percent)\n",
        "\n",
        "# Return the result as a DataFrame for better visualization\n",
        "columns_greater_than_50_percent_df = columns_greater_than_50_percent.reset_index()\n",
        "columns_greater_than_50_percent_df.columns = ['Feature', 'Percentage of -4s']\n",
        "\n",
        "# Display the DataFrame\n",
        "columns_greater_than_50_percent_df"
      ],
      "metadata": {
        "id": "_Zsgvb_ItXl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Dropping Columns with over 50% missing Data\n",
        "\n",
        "# List of columns to drop\n",
        "columns_to_drop = [\n",
        "    'CVPACE', 'TRAUMBRF', 'TRAUMEXT', 'TRAUMCHR', 'NCOTHR', 'FOCLSYM',\n",
        "    'FOCLSIGN', 'MMSEORDA', 'MMSEORLO', 'PENTAGON', 'NACCMMSE', 'LOGIMEM',\n",
        "    'MEMUNITS', 'MEMTIME', 'DIGIF', 'DIGIFLEN', 'DIGIB', 'DIGIBLEN', 'BOSTON',\n",
        "    'NPIQINFX', 'PSYCDISX', 'ABUSX', 'OTHSLEEX', 'ARTHTYPX', 'NACCOMSX',\n",
        "    'NACCOMX', 'NACCFMSX', 'NACCFMX', 'NACCAMSX', 'NACCAMX', 'RACEX'\n",
        "]\n",
        "\n",
        "# Drop the specified columns\n",
        "udslong_filtered = udslong_filtered.drop(columns=columns_to_drop)\n",
        "\n",
        "# Print the names of the columns that were dropped\n",
        "print(\"\\nColumns dropped:\")\n",
        "print(columns_to_drop)\n",
        "\n",
        "# Display the first few rows of the new dataset to verify\n",
        "print(\"\\nFirst few rows of the dataset after dropping columns:\")\n",
        "print(udslong_filtered.head())\n",
        "\n",
        "# If you want to save the updated DataFrame to a CSV file, uncomment the following line\n",
        "# udslong_filtered.to_csv('udslong_filtered_dropped.csv', index=True)"
      ],
      "metadata": {
        "id": "eHZFxfjQthv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Imputation Using KNN"
      ],
      "metadata": {
        "id": "Q7tbNhLrt6O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert -4 values to NA in the udslong_filtered DataFrame\n",
        "udslong_filtered.replace(-4, np.nan, inplace=True)\n",
        "\n",
        "# Display the first few rows of the updated DataFrame to verify\n",
        "print(\"\\nFirst few rows of the dataset after converting -4 to NA:\")\n",
        "print(udslong_filtered)"
      ],
      "metadata": {
        "id": "baSe1z5it_eJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Initialize the KNN imputer with the desired number of neighbors\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "\n",
        "# Apply the KNN imputer to the DataFrame\n",
        "udslong_imputed = pd.DataFrame(knn_imputer.fit_transform(udslong_filtered), columns=udslong_filtered.columns, index=udslong_filtered.index)\n",
        "\n",
        "# Display the first few rows of the imputed DataFrame to verify\n",
        "print(\"\\nFirst few rows of the dataset after KNN imputation:\")\n",
        "print(udslong_imputed.head())"
      ],
      "metadata": {
        "id": "dnyj74gnt9-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the imputed DataFrame to a CSV file\n",
        "udslong_imputed.to_csv('udslong_imputed.csv', index=True)\n",
        "\n",
        "# Print a message to confirm the file has been saved\n",
        "print(\"The imputed dataset has been saved as 'udslong_imputed.csv'.\")"
      ],
      "metadata": {
        "id": "-O_vBv5luI1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MRI Clean"
      ],
      "metadata": {
        "id": "NTd2w74luNO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the corrected list of variables to keep\n",
        "variables_to_keep = [\n",
        "    'LH_CAUDALANTERIORCINGULATE_GVOL', 'RH_CAUDALANTERIORCINGULATE_GVOL', 'LH_CAUDALANTERIORCINGULATE_AVGTH', 'RH_CAUDALANTERIORCINGULATE_AVGTH',\n",
        "    'LH_CAUDALMIDDLEFRONTAL_GVOL', 'RH_CAUDALMIDDLEFRONTAL_GVOL', 'LH_CAUDALMIDDLEFRONTAL_AVGTH', 'RH_CAUDALMIDDLEFRONTAL_AVGTH',\n",
        "    'LH_CUNEUS_GVOL', 'RH_CUNEUS_GVOL', 'LH_CUNEUS_AVGTH', 'RH_CUNEUS_AVGTH',\n",
        "    'LH_ENTORHINAL_GVOL', 'RH_ENTORHINAL_GVOL', 'LH_ENTORHINAL_AVGTH', 'RH_ENTORHINAL_AVGTH',\n",
        "    'LH_FUSIFORM_GVOL', 'RH_FUSIFORM_GVOL', 'LH_FUSIFORM_AVGTH', 'RH_FUSIFORM_AVGTH',\n",
        "    'LH_INFERIORPARIETAL_GVOL', 'RH_INFERIORPARIETAL_GVOL', 'LH_INFERIORPARIETAL_AVGTH', 'RH_INFERIORPARIETAL_AVGTH',\n",
        "    'LH_INFERIORTEMPORAL_GVOL', 'RH_INFERIORTEMPORAL_GVOL', 'LH_INFERIORTEMPORAL_AVGTH', 'RH_INFERIORTEMPORAL_AVGTH',\n",
        "    'LH_ISTHMUSCINGULATE_GVOL', 'RH_ISTHMUSCINGULATE_GVOL', 'LH_ISTHMUSCINGULATE_AVGTH', 'RH_ISTHMUSCINGULATE_AVGTH',\n",
        "    'LH_LATERALOCCIPITAL_GVOL', 'RH_LATERALOCCIPITAL_GVOL', 'LH_LATERALOCCIPITAL_AVGTH', 'RH_LATERALOCCIPITAL_AVGTH',\n",
        "    'LH_LATERALORBITOFRONTAL_GVOL', 'RH_LATERALORBITOFRONTAL_GVOL', 'LH_LATERALORBITOFRONTAL_AVGTH', 'RH_LATERALORBITOFRONTAL_AVGTH',\n",
        "    'LH_LINGUAL_GVOL', 'RH_LINGUAL_GVOL', 'LH_LINGUAL_AVGTH', 'RH_LINGUAL_AVGTH',\n",
        "    'LH_MEDIALORBITOFRONTAL_GVOL', 'RH_MEDIALORBITOFRONTAL_GVOL', 'LH_MEDIALORBITOFRONTAL_AVGTH', 'RH_MEDIALORBITOFRONTAL_AVGTH',\n",
        "    'LH_MIDDLETEMPORAL_GVOL', 'RH_MIDDLETEMPORAL_GVOL', 'LH_MIDDLETEMPORAL_AVGTH', 'RH_MIDDLETEMPORAL_AVGTH',\n",
        "    'LH_PARAHIPPOCAMPAL_GVOL', 'RH_PARAHIPPOCAMPAL_GVOL', 'LH_PARAHIPPOCAMPAL_AVGTH', 'RH_PARAHIPPOCAMPAL_AVGTH',\n",
        "    'LH_PARACENTRAL_GVOL', 'RH_PARACENTRAL_GVOL', 'LH_PARACENTRAL_AVGTH', 'RH_PARACENTRAL_AVGTH',\n",
        "    'LH_PARSOPERCULARIS_GVOL', 'RH_PARSOPERCULARIS_GVOL', 'LH_PARSOPERCULARIS_AVGTH', 'RH_PARSOPERCULARIS_AVGTH',\n",
        "    'LH_PARSORBITALIS_GVOL', 'RH_PARSORBITALIS_GVOL', 'LH_PARSORBITALIS_AVGTH', 'RH_PARSORBITALIS_AVGTH',\n",
        "    'LH_PARSTRIANGULARIS_GVOL', 'RH_PARSTRIANGULARIS_GVOL', 'LH_PARSTRIANGULARIS_AVGTH', 'RH_PARSTRIANGULARIS_AVGTH',\n",
        "    'LH_PERICALCARINE_GVOL', 'RH_PERICALCARINE_GVOL', 'LH_PERICALCARINE_AVGTH', 'RH_PERICALCARINE_AVGTH',\n",
        "    'LH_POSTCENTRAL_GVOL', 'RH_POSTCENTRAL_GVOL', 'LH_POSTCENTRAL_AVGTH', 'RH_POSTCENTRAL_AVGTH',\n",
        "    'LH_POSTERIORCINGULATE_GVOL', 'RH_POSTERIORCINGULATE_GVOL', 'LH_POSTERIORCINGULATE_AVGTH', 'RH_POSTERIORCINGULATE_AVGTH',\n",
        "    'LH_PRECENTRAL_GVOL', 'RH_PRECENTRAL_GVOL', 'LH_PRECENTRAL_AVGTH', 'RH_PRECENTRAL_AVGTH',\n",
        "    'LH_PRECUNEUS_GVOL', 'RH_PRECUNEUS_GVOL', 'LH_PRECUNEUS_AVGTH', 'RH_PRECUNEUS_AVGTH',\n",
        "    'LH_ROSTRALANTERIORCINGULATE_GVOL', 'RH_ROSTRALANTERIORCINGULATE_GVOL', 'LH_ROSTRALANTERIORCINGULATE_AVGTH', 'RH_ROSTRALANTERIORCINGULATE_AVGTH',\n",
        "    'LH_ROSTRALMIDDLEFRONTAL_GVOL', 'RH_ROSTRALMIDDLEFRONTAL_GVOL', 'LH_ROSTRALMIDDLEFRONTAL_AVGTH', 'RH_ROSTRALMIDDLEFRONTAL_AVGTH',\n",
        "    'LH_SUPERIORFRONTAL_GVOL', 'RH_SUPERIORFRONTAL_GVOL', 'LH_SUPERIORFRONTAL_AVGTH', 'RH_SUPERIORFRONTAL_AVGTH',\n",
        "    'LH_SUPERIORPARIETAL_GVOL', 'RH_SUPERIORPARIETAL_GVOL', 'LH_SUPERIORPARIETAL_AVGTH', 'RH_SUPERIORPARIETAL_AVGTH',\n",
        "    'LH_SUPERIORTEMPORAL_GVOL', 'RH_SUPERIORTEMPORAL_GVOL', 'LH_SUPERIORTEMPORAL_AVGTH', 'RH_SUPERIORTEMPORAL_AVGTH',\n",
        "    'LH_SUPRAMARGINAL_GVOL', 'RH_SUPRAMARGINAL_GVOL', 'LH_SUPRAMARGINAL_AVGTH', 'RH_SUPRAMARGINAL_AVGTH',\n",
        "    'LH_TRANSVERSETEMPORAL_GVOL', 'RH_TRANSVERSETEMPORAL_GVOL', 'LH_TRANSVERSETEMPORAL_AVGTH', 'RH_TRANSVERSETEMPORAL_AVGTH',\n",
        "    'LH_INSULA_GVOL', 'RH_INSULA_GVOL', 'LH_INSULA_AVGTH', 'RH_INSULA_AVGTH'\n",
        "]\n",
        "\n",
        "# Ensure that NACCID is included in the variables to keep\n",
        "variables_to_keep_with_index = variables_to_keep\n",
        "\n",
        "# Filter the mriscanlong_first_instance DataFrame\n",
        "mriscanlong_first_instance_filtered = mriscanlong_first_instance[variables_to_keep_with_index]\n",
        "\n",
        "# Ensure NACCID is set as the index for both DataFrames\n",
        "udslong_first_instance.index.name = 'NACCID'\n",
        "mriscanlong_first_instance_filtered.index.name = 'NACCID'\n",
        "\n",
        "# Merge NACCUDSD from udslong_first_instance based on the index\n",
        "mriscanlong_first_instance_filtered['NACCUDSD'] = udslong_first_instance['NACCUDSD']\n",
        "\n",
        "# Display the final DataFrame\n",
        "print(\"Filtered MRI DataFrame with NACCUDSD:\")\n",
        "print(mriscanlong_first_instance_filtered)"
      ],
      "metadata": {
        "id": "xlTrQZlruO9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the imputed DataFrame to a CSV file\n",
        "mriscanlong_first_instance_filtered.to_csv('mriscanclean.csv', index=True)\n",
        "\n",
        "# Print a message to confirm the file has been saved\n",
        "print(\"The imputed dataset has been saved as 'udslong_imputed.csv'.\")"
      ],
      "metadata": {
        "id": "xHReLqS1yL6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Graph Neural Networks"
      ],
      "metadata": {
        "id": "ozggbcPzuf-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Pytorch Geometric Library\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "id": "3LwMAlxPujbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS Structured Graph Neural Network"
      ],
      "metadata": {
        "id": "Da54d8zevCpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "udslong_imputed = 'GoogleDriveFileId'\n",
        "downloaded = drive.CreateFile({'id': udslong_imputed})\n",
        "downloaded.GetContentFile(\"GoogleDriveFileName.csv\")"
      ],
      "metadata": {
        "id": "K4pXQusbvGRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# Define the feature groups\n",
        "input_demo_feats = ['SEX', 'HISPANIC', 'HISPOR', 'RACE', 'RACEX', 'PRIMLANG', 'EDUC', 'MARISTAT', 'NACCLIVS', 'INDEPEND', 'RESIDENC', 'NACCNIHR','NACCAGE']\n",
        "input_fam_hist_feats = ['NACCFAM', 'NACCMOM', 'NACCDAD', 'NACCAM', 'NACCAMX', 'NACCAMS', 'NACCAMSX', 'NACCFM', 'NACCFMX', 'NACCFMS', 'NACCFMSX', 'NACCOM', 'NACCOMX', 'NACCOMS', 'NACCOMSX', 'NACCFADM', 'NACCFFTD']\n",
        "input_patient_hist_feats = ['ANYMEDS', 'TOBAC30', 'TOBAC100', 'SMOKYRS', 'PACKSPER', 'QUITSMOK', 'CVHATT', 'CVAFIB', 'CVANGIO', 'CVBYPASS', 'CVPACDEF', 'CVPACE', 'CVCHF', 'CVOTHR', 'CBSTROKE', 'NACCSTYR', 'CBTIA', 'NACCTIYR', 'SEIZURES', 'NACCTBI', 'TBI', 'TBIBRIEF', 'TRAUMBRF', 'TBIEXTEN', 'TRAUMEXT', 'TBIWOLOS', 'TRAUMCHR', 'TBIYEAR', 'NCOTHR', 'DIABETES', 'DIABTYPE', 'HYPERTEN', 'HYPERCHO', 'B12DEF', 'THYROID', 'ARTHRIT', 'ARTHTYPE', 'ARTHTYPX', 'ARTHUPEX', 'ARTHLOEX', 'ARTHSPIN', 'ARTHUNK', 'INCONTU', 'INCONTF', 'APNEA', 'RBD', 'INSOMN', 'OTHSLEEP', 'OTHSLEEX', 'ALCOHOL', 'ABUSOTHR', 'ABUSX', 'PTSD', 'BIPOLAR', 'SCHIZ', 'DEP2YRS', 'DEPOTHR', 'ANXIETY', 'OCD', 'NPSYDEV', 'PSYCDIS', 'PSYCDISX', 'NACCAAAS', 'NACCAANX', 'NACCAC', 'NACCACEI', 'NACCADEP', 'NACCAHTN', 'NACCAMD', 'NACCANGI', 'NACCAPSY', 'NACCBETA', 'NACCCCBS', 'NACCDBMD', 'NACCDIUR', 'NACCEMD', 'NACCEPMD', 'NACCHTNC', 'NACCLIPL', 'NACCNSD', 'NACCPDMD', 'NACCVASD']\n",
        "input_physical_feats = ['HEIGHT','WEIGHT', 'BPSYS', 'BPDIAS', 'HRATE', 'VISION', 'VISCORR','VISWCORR', 'HEARING', 'HEARAID', 'HEARWAID','NACCBMI','FOCLSYM','FOCLSIGN','NACCNREX', 'NORMEXAM']\n",
        "input_npi_feats = ['NPIQINF', 'NPIQINFX', 'DEL', 'DELSEV', 'HALL','HALLSEV', 'AGIT', 'AGITSEV', 'DEPD', 'DEPDSEV', 'ANX', 'ANXSEV','ELAT', 'ELATSEV', 'APA', 'APASEV', 'DISN', 'DISNSEV', 'IRR','IRRSEV', 'MOT', 'MOTSEV', 'NITE', 'NITESEV', 'APP', 'APPSEV']\n",
        "input_gds_feats = ['NOGDS', 'SATIS', 'DROPACT', 'EMPTY', 'BORED', 'SPIRITS', 'AFRAID','HAPPY', 'HELPLESS', 'STAYHOME', 'MEMPROB', 'WONDRFUL', 'WRTHLESS','ENERGY', 'HOPELESS', 'BETTER', 'NACCGDS']\n",
        "input_faq_feats = ['BILLS', 'TAXES','SHOPPING', 'GAMES', 'STOVE','MEALPREP', 'EVENTS', 'PAYATTN','REMDATES', 'TRAVEL', 'DECSUB']\n",
        "input_np_feats = ['MMSEORDA','MMSEORLO', 'PENTAGON', 'NACCMMSE', 'LOGIMEM', 'MEMUNITS','MEMTIME', 'DIGIF', 'DIGIFLEN', 'DIGIB', 'DIGIBLEN', 'ANIMALS','VEG', 'TRAILA', 'TRAILARR', 'TRAILALI', 'TRAILB', 'TRAILBRR','TRAILBLI', 'BOSTON', 'MOCATOTS']\n",
        "input_gene_feats = ['NACCAPOE']\n",
        "\n",
        "# Combine all input feature groups into a single list\n",
        "all_feats = (\n",
        "    input_demo_feats + input_fam_hist_feats + input_patient_hist_feats +\n",
        "    input_physical_feats + input_npi_feats + input_gds_feats +\n",
        "    input_faq_feats + input_np_feats + input_gene_feats\n",
        ")\n",
        "\n",
        "# Variables to remove\n",
        "variables_to_remove = [\n",
        "    'NPIQINFX', 'PSYCDISX', 'ABUSX', 'OTHSLEEX', 'ARTHTYPX', 'NACCOMSX',\n",
        "    'NACCOMX', 'NACCFMSX', 'NACCFMX', 'NACCAMSX', 'NACCAMX', 'RACEX',\n",
        "    'CVPACE', 'TRAUMBRF', 'TRAUMEXT', 'TRAUMCHR', 'NCOTHR', 'FOCLSYM',\n",
        "    'FOCLSIGN', 'MMSEORDA', 'MMSEORLO', 'PENTAGON', 'NACCMMSE', 'LOGIMEM',\n",
        "    'MEMUNITS', 'MEMTIME', 'DIGIF', 'DIGIFLEN', 'DIGIB', 'DIGIBLEN', 'BOSTON', 'NACCSTYR', 'NACCTIYR', 'TBIYEAR'\n",
        "]\n",
        "\n",
        "# Filter out the variables to remove\n",
        "filtered_feats = [feat for feat in all_feats if feat not in variables_to_remove]\n",
        "\n",
        "# Initialize the adjacency matrix with zeros\n",
        "adj_matrix = np.zeros((len(filtered_feats), len(filtered_feats)))\n",
        "\n",
        "# Update the adjacency matrix: fully connected graph within each feature group\n",
        "def update_adj_matrix(features, matrix):\n",
        "    indices = [filtered_feats.index(feat) for feat in features if feat in filtered_feats]\n",
        "    for i in indices:\n",
        "        for j in indices:\n",
        "            matrix[i][j] = 1\n",
        "\n",
        "# Apply the adjacency update for each feature group\n",
        "feature_groups = [\n",
        "    input_demo_feats, input_fam_hist_feats, input_patient_hist_feats,\n",
        "    input_physical_feats, input_npi_feats, input_gds_feats,\n",
        "    input_faq_feats, input_np_feats, input_gene_feats\n",
        "]\n",
        "\n",
        "for group in feature_groups:\n",
        "    update_adj_matrix(group, adj_matrix)\n",
        "\n",
        "# Convert the adjacency matrix to a DataFrame for better visualization\n",
        "adj_df = pd.DataFrame(adj_matrix, index=filtered_feats, columns=filtered_feats)\n",
        "\n",
        "# Display the adjacency matrix\n",
        "print(\"Adjacency Matrix:\")\n",
        "print(adj_df)"
      ],
      "metadata": {
        "id": "yj4cBpNYvHIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load the corrected dataset\n",
        "dataset_path = 'udslong_imputed.csv'\n",
        "uds_df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Binarize the NACCUDSD column\n",
        "uds_df['NACCUDSD'] = uds_df['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0)\n",
        "\n",
        "# Extract labels\n",
        "labels = uds_df['NACCUDSD'].values\n",
        "\n",
        "# Remove NACCUDSD and NACCID from the feature groups\n",
        "features_df = uds_df.drop(columns=['NACCUDSD', 'NACCID'])\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = features_df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Encode non-numeric features\n",
        "if len(non_numeric_cols) > 0:\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    encoded_features = encoder.fit_transform(features_df[non_numeric_cols])\n",
        "    # Combine encoded non-numeric features with numeric features\n",
        "    features_combined = np.hstack((features_df[numeric_cols].values, encoded_features))\n",
        "else:\n",
        "    features_combined = features_df[numeric_cols].values\n",
        "\n",
        "# Normalize the numeric features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features_combined)\n",
        "\n",
        "# Reshape the features to (num_patients, num_regions, num_features)\n",
        "num_patients = scaled_features.shape[0]\n",
        "num_regions = scaled_features.shape[1]\n",
        "num_features = 1\n",
        "\n",
        "features = scaled_features.reshape(num_patients, num_regions, num_features)\n",
        "\n",
        "# Create an adjacency matrix with only diagonal elements as 1\n",
        "adj_matrix = np.eye(num_regions)\n",
        "\n",
        "# Convert to PyTorch Geometric data\n",
        "data_list = []\n",
        "for i in range(num_patients):\n",
        "    edge_index = np.array(np.nonzero(adj_matrix))\n",
        "    x = torch.tensor(features[i], dtype=torch.float)\n",
        "    y = torch.tensor([labels[i]], dtype=torch.long)\n",
        "    data_list.append(Data(x=x, edge_index=torch.tensor(edge_index, dtype=torch.long), y=y))\n",
        "\n",
        "# Define the GNN model with 4 layers\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 64)\n",
        "        self.conv2 = GCNConv(64, 32)\n",
        "        self.conv3 = GCNConv(32, 16)\n",
        "        self.conv4 = GCNConv(16, 8)\n",
        "        self.fc = torch.nn.Linear(8, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = global_mean_pool(x, batch)  # Aggregate node features to graph-level features\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "def initialize_model():\n",
        "    model = GNN()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    return model, optimizer, criterion\n",
        "\n",
        "# Training loop\n",
        "def train(model, optimizer, criterion, train_loader):\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation function\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += int((pred == data.y).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(data_list):\n",
        "    train_data_list = [data_list[i] for i in train_index]\n",
        "    test_data_list = [data_list[i] for i in test_index]\n",
        "\n",
        "    train_loader = DataLoader(train_data_list, batch_size=20, shuffle=True)\n",
        "    test_loader = DataLoader(test_data_list, batch_size=20, shuffle=False)\n",
        "\n",
        "    model, optimizer, criterion = initialize_model()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    test_acc = test(model, test_loader)\n",
        "    fold_accuracies.append(test_acc)\n",
        "    print(f'Test Accuracy for fold: {test_acc:.4f}')\n",
        "\n",
        "average_accuracy = np.mean(fold_accuracies)\n",
        "std_accuracy = np.std(fold_accuracies)\n",
        "print(f'Average Test Accuracy: {average_accuracy:.4f}')\n",
        "print(f'Standard Deviation of Test Accuracy: {std_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "09BkSA4EvLkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS Unstructured Graph Neural Network"
      ],
      "metadata": {
        "id": "MlgGsNapw0Br"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Load the corrected dataset\n",
        "dataset_path = 'udslong_imputed.csv'\n",
        "uds_df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Binarize the NACCUDSD column\n",
        "uds_df['NACCUDSD'] = uds_df['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0)\n",
        "\n",
        "# Extract labels\n",
        "labels = uds_df['NACCUDSD'].values\n",
        "\n",
        "# Remove NACCUDSD and NACCID from the feature groups\n",
        "features_df = uds_df.drop(columns=['NACCUDSD', 'NACCID'])\n",
        "\n",
        "# Separate numeric and non-numeric columns\n",
        "numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = features_df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "# Encode non-numeric features\n",
        "if len(non_numeric_cols) > 0:\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    encoded_features = encoder.fit_transform(features_df[non_numeric_cols])\n",
        "    # Combine encoded non-numeric features with numeric features\n",
        "    features_combined = np.hstack((features_df[numeric_cols].values, encoded_features))\n",
        "else:\n",
        "    features_combined = features_df[numeric_cols].values\n",
        "\n",
        "# Normalize the numeric features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features_combined)\n",
        "\n",
        "# Reshape the features to (num_patients, num_regions, num_features)\n",
        "num_patients = scaled_features.shape[0]\n",
        "num_regions = scaled_features.shape[1]\n",
        "num_features = 1\n",
        "\n",
        "features = scaled_features.reshape(num_patients, num_regions, num_features)\n",
        "\n",
        "# Create an identity matrix as the adjacency matrix\n",
        "adj_matrix = np.eye(num_regions)\n",
        "\n",
        "# Convert to PyTorch Geometric data\n",
        "data_list = []\n",
        "for i in range(num_patients):\n",
        "    edge_index = np.array(np.nonzero(adj_matrix))\n",
        "    x = torch.tensor(features[i], dtype=torch.float)\n",
        "    y = torch.tensor([labels[i]], dtype=torch.long)\n",
        "    data_list.append(Data(x=x, edge_index=torch.tensor(edge_index, dtype=torch.long), y=y))\n",
        "\n",
        "# Define the GNN model with 4 layers\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_features, 64)\n",
        "        self.conv2 = GCNConv(64, 32)\n",
        "        self.conv3 = GCNConv(32, 16)\n",
        "        self.conv4 = GCNConv(16, 8)\n",
        "        self.fc = torch.nn.Linear(8, 2)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = global_mean_pool(x, batch)  # Aggregate node features to graph-level features\n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Initialize model, loss, and optimizer\n",
        "def initialize_model():\n",
        "    model = GNN()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    return model, optimizer, criterion\n",
        "\n",
        "# Training loop\n",
        "def train(model, optimizer, criterion, train_loader):\n",
        "    model.train()\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation function\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        out = model(data)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += int((pred == data.y).sum())\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold_accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(data_list):\n",
        "    train_data_list = [data_list[i] for i in train_index]\n",
        "    test_data_list = [data_list[i] for i in test_index]\n",
        "\n",
        "    train_loader = DataLoader(train_data_list, batch_size=20, shuffle=True)\n",
        "    test_loader = DataLoader(test_data_list, batch_size=20, shuffle=False)\n",
        "\n",
        "    model, optimizer, criterion = initialize_model()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    test_acc = test(model, test_loader)\n",
        "    fold_accuracies.append(test_acc)\n",
        "    print(f'Test Accuracy for fold: {test_acc:.4f}')\n",
        "\n",
        "average_accuracy = np.mean(fold_accuracies)\n",
        "std_accuracy = np.std(fold_accuracies)\n",
        "print(f'Average Test Accuracy: {average_accuracy:.4f}')\n",
        "print(f'Standard Deviation of Test Accuracy: {std_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "PPS9MUR4w7qx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MRI Structured Graph Neural Network"
      ],
      "metadata": {
        "id": "IYoiO-jew9ZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "mri_adjacency_matrix = 'GoogleDriveFileID'\n",
        "downloaded = drive.CreateFile({'id': mri_adjacency_matrix})\n",
        "downloaded.GetContentFile(\"GoogleDriveFileName.csv\")\n",
        "\n",
        "mriscanclean = 'GoogleDriveFileID'\n",
        "downloaded = drive.CreateFile({'id': mriscanclean})\n",
        "downloaded.GetContentFile(\"GoogleDriveFileName.csv\")"
      ],
      "metadata": {
        "id": "gZRd54RZxBbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mriadjacencymatrix=pd.read_csv('combined_adjacency_matrix.csv',index_col=0,header=0)\n",
        "mriscanclean=pd.read_csv('mriscanclean.csv',index_col=0,header=0)"
      ],
      "metadata": {
        "id": "SPa6b8ciyfwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data, DataLoader, Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the MRI dataset\n",
        "mriscanclean = pd.read_csv('mriscanclean.csv', index_col=0)\n",
        "\n",
        "# Preprocess the MRI dataset\n",
        "vol_columns = [col for col in mriscanclean.columns if 'GVOL' in col]\n",
        "thick_columns = [col for col in mriscanclean.columns if 'AVGTH' in col]\n",
        "scaler_vol = StandardScaler()\n",
        "scaler_thick = StandardScaler()\n",
        "mriscanclean[vol_columns] = scaler_vol.fit_transform(mriscanclean[vol_columns])\n",
        "mriscanclean[thick_columns] = scaler_thick.fit_transform(mriscanclean[thick_columns])\n",
        "num_patients = mriscanclean.shape[0]\n",
        "num_nodes = 62  # 31 regions for each hemisphere\n",
        "num_features = 2  # gray volume and average thickness\n",
        "mri_patient_features = np.zeros((num_patients, num_nodes, num_features))\n",
        "for i in range(num_patients):\n",
        "    mri_patient_features[i, :, 0] = mriscanclean.iloc[i][vol_columns].values\n",
        "    mri_patient_features[i, :, 1] = mriscanclean.iloc[i][thick_columns].values\n",
        "mri_labels = mriscanclean['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0).values\n",
        "\n",
        "# Load the adjacency matrix\n",
        "mri_adj_matrix = pd.read_csv('combined_adjacency_matrix.csv', index_col=0, header=0).values\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)  # First GCN layer: in_channels -> 64 features\n",
        "        self.conv2 = GCNConv(64, 32)           # Second GCN layer: 64 features -> 32 features\n",
        "        self.conv3 = GCNConv(32, 16)           # Third GCN layer: 32 features -> 16 features\n",
        "        self.conv4 = GCNConv(16, 8)            # Fourth GCN layer: 16 features -> 8 features\n",
        "        self.fc = torch.nn.Linear(8, 1)        # Fully connected layer: 8 features -> 1 feature (output)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after first GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after second GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after third GCN layer\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after fourth GCN layer\n",
        "        x = global_mean_pool(x, data.batch)   # Global mean pooling\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)               # Sigmoid activation in the fully connected layer\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, patient_features, adjacency_matrix, labels):\n",
        "        self.patient_features = patient_features\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.patient_features[idx], dtype=torch.float)\n",
        "        edge_index = torch.tensor(np.array(np.nonzero(self.adjacency_matrix)), dtype=torch.long)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for train_index, test_index in kf.split(mri_labels):\n",
        "    # Prepare MRI data\n",
        "    mri_train_features, mri_test_features = mri_patient_features[train_index], mri_patient_features[test_index]\n",
        "    mri_train_labels, mri_test_labels = mri_labels[train_index], mri_labels[test_index]\n",
        "    mri_train_dataset = BrainDataset(mri_train_features, mri_adj_matrix, mri_train_labels)\n",
        "    mri_test_dataset = BrainDataset(mri_test_features, mri_adj_matrix, mri_test_labels)\n",
        "    mri_train_loader = DataLoader(mri_train_dataset, batch_size=20, shuffle=True)\n",
        "    mri_test_loader = DataLoader(mri_test_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GNN(in_channels=2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for data in mri_train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in mri_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            preds = (out > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(data.y.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f'Fold Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print cross-validation results\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "print(f'5-Fold Cross-Validation Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "phmDELIzyq7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MRI Unstructured Graph Neural Network"
      ],
      "metadata": {
        "id": "-qFuuHbgy9fW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data, DataLoader, Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the MRI dataset\n",
        "mriscanclean = pd.read_csv('mriscanclean.csv', index_col=0)\n",
        "\n",
        "# Preprocess the MRI dataset\n",
        "vol_columns = [col for col in mriscanclean.columns if 'GVOL' in col]\n",
        "thick_columns = [col for col in mriscanclean.columns if 'AVGTH' in col]\n",
        "scaler_vol = StandardScaler()\n",
        "scaler_thick = StandardScaler()\n",
        "mriscanclean[vol_columns] = scaler_vol.fit_transform(mriscanclean[vol_columns])\n",
        "mriscanclean[thick_columns] = scaler_thick.fit_transform(mriscanclean[thick_columns])\n",
        "num_patients = mriscanclean.shape[0]\n",
        "num_nodes = 62  # 31 regions for each hemisphere\n",
        "num_features = 2  # gray volume and average thickness\n",
        "mri_patient_features = np.zeros((num_patients, num_nodes, num_features))\n",
        "for i in range(num_patients):\n",
        "    mri_patient_features[i, :, 0] = mriscanclean.iloc[i][vol_columns].values\n",
        "    mri_patient_features[i, :, 1] = mriscanclean.iloc[i][thick_columns].values\n",
        "mri_labels = mriscanclean['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0).values\n",
        "\n",
        "# Create an identity adjacency matrix for MRI\n",
        "mri_adj_matrix = np.eye(num_nodes)  # Identity matrix for MRI\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)  # First GCN layer: in_channels -> 64 features\n",
        "        self.conv2 = GCNConv(64, 32)           # Second GCN layer: 64 features -> 32 features\n",
        "        self.conv3 = GCNConv(32, 16)           # Third GCN layer: 32 features -> 16 features\n",
        "        self.conv4 = GCNConv(16, 8)            # Fourth GCN layer: 16 features -> 8 features\n",
        "        self.fc = torch.nn.Linear(8, 1)        # Fully connected layer: 8 features -> 1 feature (output)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after first GCN layer\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after second GCN layer\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after third GCN layer\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)                         # ReLU activation after fourth GCN layer\n",
        "        x = global_mean_pool(x, data.batch)   # Global mean pooling\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)               # Sigmoid activation in the fully connected layer\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, patient_features, adjacency_matrix, labels):\n",
        "        self.patient_features = patient_features\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.patient_features[idx], dtype=torch.float)\n",
        "        edge_index = torch.tensor(np.array(np.nonzero(self.adjacency_matrix)), dtype=torch.long)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for train_index, test_index in kf.split(mri_labels):\n",
        "    # Prepare MRI data\n",
        "    mri_train_features, mri_test_features = mri_patient_features[train_index], mri_patient_features[test_index]\n",
        "    mri_train_labels, mri_test_labels = mri_labels[train_index], mri_labels[test_index]\n",
        "    mri_train_dataset = BrainDataset(mri_train_features, mri_adj_matrix, mri_train_labels)\n",
        "    mri_test_dataset = BrainDataset(mri_test_features, mri_adj_matrix, mri_test_labels)\n",
        "    mri_train_loader = DataLoader(mri_train_dataset, batch_size=20, shuffle=True)\n",
        "    mri_test_loader = DataLoader(mri_test_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "    # Initialize model\n",
        "    model = GNN(in_channels=2).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    for epoch in range(20):\n",
        "        for data in mri_train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in mri_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = model(data)\n",
        "            preds = (out > 0.5).float()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(data.y.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f'Fold Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Print cross-validation results\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "std_accuracy = np.std(accuracies)\n",
        "print(f'5-Fold Cross-Validation Accuracy: {mean_accuracy:.4f} ± {std_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "smrcrsZxzK_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS + MRI - Determining Best Combination of Weights"
      ],
      "metadata": {
        "id": "VCy2Mj7FzBVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data, DataLoader, Dataset\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load and preprocess UDS dataset\n",
        "uds_df = pd.read_csv('udslong_imputed.csv')\n",
        "uds_df['NACCUDSD'] = uds_df['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0)\n",
        "uds_labels = uds_df['NACCUDSD'].values\n",
        "uds_features_df = uds_df.drop(columns=['NACCUDSD', 'NACCID'])\n",
        "\n",
        "numeric_cols = uds_features_df.select_dtypes(include=[np.number]).columns\n",
        "non_numeric_cols = uds_features_df.select_dtypes(exclude=[np.number]).columns\n",
        "\n",
        "if len(non_numeric_cols) > 0:\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    encoded_features = encoder.fit_transform(uds_features_df[non_numeric_cols])\n",
        "    uds_features_combined = np.hstack((uds_features_df[numeric_cols].values, encoded_features))\n",
        "else:\n",
        "    uds_features_combined = uds_features_df[numeric_cols].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaled_uds_features = scaler.fit_transform(uds_features_combined)\n",
        "uds_adj_matrix = np.eye(scaled_uds_features.shape[1])\n",
        "\n",
        "# Load and preprocess MRI dataset\n",
        "mriscanclean = pd.read_csv('mriscanclean.csv', index_col=0)\n",
        "vol_columns = [col for col in mriscanclean.columns if 'GVOL' in col]\n",
        "thick_columns = [col for col in mriscanclean.columns if 'AVGTH' in col]\n",
        "scaler_vol = StandardScaler()\n",
        "scaler_thick = StandardScaler()\n",
        "mriscanclean[vol_columns] = scaler_vol.fit_transform(mriscanclean[vol_columns])\n",
        "mriscanclean[thick_columns] = scaler_thick.fit_transform(mriscanclean[thick_columns])\n",
        "num_patients = mriscanclean.shape[0]\n",
        "num_nodes = 62\n",
        "num_features = 2\n",
        "mri_patient_features = np.zeros((num_patients, num_nodes, num_features))\n",
        "for i in range(num_patients):\n",
        "    mri_patient_features[i, :, 0] = mriscanclean.iloc[i][vol_columns].values\n",
        "    mri_patient_features[i, :, 1] = mriscanclean.iloc[i][thick_columns].values\n",
        "mri_labels = mriscanclean['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0).values\n",
        "mri_adj_matrix = pd.read_csv('combined_adjacency_matrix.csv', index_col=0, header=0).values\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)\n",
        "        self.conv2 = GCNConv(64, 32)\n",
        "        self.conv3 = GCNConv(32, 16)\n",
        "        self.conv4 = GCNConv(16, 8)\n",
        "        self.fc = torch.nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, patient_features, adjacency_matrix, labels):\n",
        "        self.patient_features = patient_features\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.patient_features[idx], dtype=torch.float)\n",
        "        edge_index = torch.tensor(np.array(np.nonzero(self.adjacency_matrix)), dtype=torch.long)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "def initialize_model(in_channels):\n",
        "    model = GNN(in_channels=in_channels)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    return model, optimizer, criterion\n",
        "\n",
        "def train(model, optimizer, criterion, loader):\n",
        "    model.train()\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data)\n",
        "        loss = criterion(out, data.y.view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            out = model(data)\n",
        "            preds.extend(out.cpu().numpy())\n",
        "    return np.array(preds).flatten()\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "all_weights = [(i / 10, 1 - i / 10) for i in range(1, 10)]\n",
        "best_combined_accuracy = 0\n",
        "best_weights = (0, 0)\n",
        "\n",
        "for uds_weight, mri_weight in all_weights:\n",
        "    combined_accuracies = []\n",
        "\n",
        "    for train_index, test_index in kf.split(uds_labels):\n",
        "        # Prepare UDS data\n",
        "        uds_train_features, uds_test_features = scaled_uds_features[train_index], scaled_uds_features[test_index]\n",
        "        uds_train_labels, uds_test_labels = uds_labels[train_index], uds_labels[test_index]\n",
        "        uds_train_data_list = [Data(x=torch.tensor(uds_train_features[i].reshape(-1, 1), dtype=torch.float),\n",
        "                                    edge_index=torch.tensor(np.array(np.nonzero(uds_adj_matrix)), dtype=torch.long),\n",
        "                                    y=torch.tensor([uds_train_labels[i]], dtype=torch.float)) for i in range(len(uds_train_labels))]\n",
        "        uds_test_data_list = [Data(x=torch.tensor(uds_test_features[i].reshape(-1, 1), dtype=torch.float),\n",
        "                                   edge_index=torch.tensor(np.array(np.nonzero(uds_adj_matrix)), dtype=torch.long),\n",
        "                                   y=torch.tensor([uds_test_labels[i]], dtype=torch.float)) for i in range(len(uds_test_labels))]\n",
        "        uds_train_loader = DataLoader(uds_train_data_list, batch_size=20, shuffle=True)\n",
        "        uds_test_loader = DataLoader(uds_test_data_list, batch_size=20, shuffle=False)\n",
        "\n",
        "        # Prepare MRI data\n",
        "        mri_train_features, mri_test_features = mri_patient_features[train_index], mri_patient_features[test_index]\n",
        "        mri_train_labels, mri_test_labels = mri_labels[train_index], mri_labels[test_index]\n",
        "        mri_train_dataset = BrainDataset(mri_train_features, mri_adj_matrix, mri_train_labels)\n",
        "        mri_test_dataset = BrainDataset(mri_test_features, mri_adj_matrix, mri_test_labels)\n",
        "        mri_train_loader = DataLoader(mri_train_dataset, batch_size=20, shuffle=True)\n",
        "        mri_test_loader = DataLoader(mri_test_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "        # Initialize models\n",
        "        uds_model, uds_optimizer, uds_criterion = initialize_model(1)\n",
        "        mri_model, mri_optimizer, mri_criterion = initialize_model(2)\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        uds_model.to(device)\n",
        "        mri_model.to(device)\n",
        "\n",
        "        # Train UDS model\n",
        "        for epoch in range(10):\n",
        "            train(uds_model, uds_optimizer, uds_criterion, uds_train_loader)\n",
        "\n",
        "        # Train MRI model\n",
        "        for epoch in range(20):\n",
        "            train(mri_model, mri_optimizer, mri_criterion, mri_train_loader)\n",
        "\n",
        "        # Get predictions for UDS and MRI\n",
        "        uds_preds = test(uds_model, uds_test_loader)\n",
        "        mri_preds = test(mri_model, mri_test_loader)\n",
        "\n",
        "        # Combine predictions using the weights\n",
        "        combined_preds = (uds_preds * uds_weight) + (mri_preds * mri_weight)\n",
        "        combined_preds_binary = (combined_preds > 0.5).astype(int)\n",
        "        combined_accuracy = accuracy_score(uds_test_labels, combined_preds_binary)\n",
        "\n",
        "        combined_accuracies.append(combined_accuracy)\n",
        "\n",
        "    mean_combined_accuracy = np.mean(combined_accuracies)\n",
        "    std_combined_accuracy = np.std(combined_accuracies)\n",
        "    print(f'Weights: UDS {uds_weight:.1f}, MRI {mri_weight:.1f} - Combined 5-Fold Accuracy: {mean_combined_accuracy:.4f} ± {std_combined_accuracy:.4f}')\n",
        "\n",
        "    if mean_combined_accuracy > best_combined_accuracy:\n",
        "        best_combined_accuracy = mean_combined_accuracy\n",
        "        best_weights = (uds_weight, mri_weight)\n",
        "\n",
        "print(f'Best Weights: UDS {best_weights[0]:.1f}, MRI {best_weights[1]:.1f} - Best Combined 5-Fold Accuracy: {best_combined_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "jQcP__mS2uYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS + MRI Structured Graph Neural Network"
      ],
      "metadata": {
        "id": "0kGxUwyC2wN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data, DataLoader, Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the datasets\n",
        "uds_df = pd.read_csv('udslong_imputed.csv')\n",
        "mriscanclean = pd.read_csv('mriscanclean.csv', index_col=0)\n",
        "\n",
        "# Preprocess the UDS dataset\n",
        "uds_df['NACCUDSD'] = uds_df['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0)\n",
        "uds_features = uds_df.drop(columns=['NACCUDSD'])\n",
        "uds_labels = uds_df['NACCUDSD'].values\n",
        "uds_features = uds_features.apply(pd.to_numeric, errors='coerce')\n",
        "uds_features.fillna(0, inplace=True)\n",
        "scaler_uds = StandardScaler()\n",
        "scaled_uds_features = scaler_uds.fit_transform(uds_features.values)\n",
        "uds_adj_matrix = np.eye(scaled_uds_features.shape[1])\n",
        "\n",
        "# Preprocess the MRI dataset\n",
        "vol_columns = [col for col in mriscanclean.columns if 'GVOL' in col]\n",
        "thick_columns = [col for col in mriscanclean.columns if 'AVGTH' in col]\n",
        "scaler_vol = StandardScaler()\n",
        "scaler_thick = StandardScaler()\n",
        "mriscanclean[vol_columns] = scaler_vol.fit_transform(mriscanclean[vol_columns])\n",
        "mriscanclean[thick_columns] = scaler_thick.fit_transform(mriscanclean[thick_columns])\n",
        "num_patients = mriscanclean.shape[0]\n",
        "num_nodes = 62\n",
        "num_features = 2\n",
        "mri_patient_features = np.zeros((num_patients, num_nodes, num_features))\n",
        "for i in range(num_patients):\n",
        "    mri_patient_features[i, :, 0] = mriscanclean.iloc[i][vol_columns].values\n",
        "    mri_patient_features[i, :, 1] = mriscanclean.iloc[i][thick_columns].values\n",
        "mri_labels = mriscanclean['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0).values\n",
        "mri_adj_matrix = pd.read_csv('combined_adjacency_matrix.csv', index_col=0, header=0).values\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)\n",
        "        self.conv2 = GCNConv(64, 32)\n",
        "        self.conv3 = GCNConv(32, 16)\n",
        "        self.conv4 = GCNConv(16, 8)\n",
        "        self.fc = torch.nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, patient_features, adjacency_matrix, labels):\n",
        "        self.patient_features = patient_features\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.patient_features[idx], dtype=torch.float)\n",
        "        edge_index = torch.tensor(np.array(np.nonzero(self.adjacency_matrix)), dtype=torch.long)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "combined_accuracies = []\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for train_index, test_index in kf.split(uds_labels):\n",
        "    # Prepare UDS data\n",
        "    uds_train_features, uds_test_features = scaled_uds_features[train_index], scaled_uds_features[test_index]\n",
        "    uds_train_labels, uds_test_labels = uds_labels[train_index], uds_labels[test_index]\n",
        "    uds_train_data_list = [Data(x=torch.tensor(uds_train_features[i].reshape(-1, 1), dtype=torch.float),\n",
        "                                edge_index=torch.tensor(np.array(np.nonzero(uds_adj_matrix)), dtype=torch.long),\n",
        "                                y=torch.tensor([uds_train_labels[i]], dtype=torch.float)) for i in range(len(uds_train_labels))]\n",
        "    uds_test_data_list = [Data(x=torch.tensor(uds_test_features[i].reshape(-1, 1), dtype=torch.float),\n",
        "                               edge_index=torch.tensor(np.array(np.nonzero(uds_adj_matrix)), dtype=torch.long),\n",
        "                               y=torch.tensor([uds_test_labels[i]], dtype=torch.float)) for i in range(len(uds_test_labels))]\n",
        "    uds_train_loader = DataLoader(uds_train_data_list, batch_size=20, shuffle=True)\n",
        "    uds_test_loader = DataLoader(uds_test_data_list, batch_size=20, shuffle=False)\n",
        "\n",
        "    # Prepare MRI data\n",
        "    mri_train_features, mri_test_features = mri_patient_features[train_index], mri_patient_features[test_index]\n",
        "    mri_train_labels, mri_test_labels = mri_labels[train_index], mri_labels[test_index]\n",
        "    mri_train_dataset = BrainDataset(mri_train_features, mri_adj_matrix, mri_train_labels)\n",
        "    mri_test_dataset = BrainDataset(mri_test_features, mri_adj_matrix, mri_test_labels)\n",
        "    mri_train_loader = DataLoader(mri_train_dataset, batch_size=20, shuffle=True)\n",
        "    mri_test_loader = DataLoader(mri_test_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "    # Train UDS GNN\n",
        "    uds_model = GNN(in_channels=1).to(device)\n",
        "    optimizer = torch.optim.Adam(uds_model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    uds_model.train()\n",
        "    for epoch in range(20):\n",
        "        for data in uds_train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = uds_model(data)\n",
        "            loss = criterion(out, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Train MRI GNN\n",
        "    mri_model = GNN(in_channels=2).to(device)\n",
        "    optimizer = torch.optim.Adam(mri_model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    mri_model.train()\n",
        "    for epoch in range(10):\n",
        "        for data in mri_train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = mri_model(data)\n",
        "            loss = criterion(out, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Get predictions for UDS and MRI\n",
        "    uds_model.eval()\n",
        "    mri_model.eval()\n",
        "    uds_preds = []\n",
        "    mri_preds = []\n",
        "    with torch.no_grad():\n",
        "        for data in uds_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = uds_model(data)\n",
        "            uds_preds.extend(out.cpu().numpy())\n",
        "\n",
        "        for data in mri_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = mri_model(data)\n",
        "            mri_preds.extend(out.cpu().numpy())\n",
        "\n",
        "    uds_preds = np.array(uds_preds).flatten()\n",
        "    mri_preds = np.array(mri_preds).flatten()\n",
        "\n",
        "    # Weigh UDS predictions higher\n",
        "    combined_preds = (uds_preds * 0.7) + (mri_preds * 0.3)\n",
        "    combined_preds_binary = (combined_preds > 0.5).astype(int)\n",
        "    combined_accuracy = accuracy_score(uds_test_labels, combined_preds_binary)\n",
        "    combined_accuracies.append(combined_accuracy)\n",
        "    print(f'Fold Test Accuracy: {combined_accuracy:.4f}')\n",
        "\n",
        "# Print combined 5-fold cross-validation accuracy\n",
        "mean_combined_accuracy = np.mean(combined_accuracies)\n",
        "std_combined_accuracy = np.std(combined_accuracies)\n",
        "print(f'Combined 5-Fold Cross-Validation Accuracy: {mean_combined_accuracy:.4f} ± {std_combined_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "GpVDfCFszSrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UDS + MRI Unstructured Graph Neural Network"
      ],
      "metadata": {
        "id": "Ss2t9t3x3OwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.data import Data, DataLoader, Dataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the datasets\n",
        "uds_df = pd.read_csv('udslong_imputed.csv')\n",
        "mriscanclean = pd.read_csv('mriscanclean.csv', index_col=0)\n",
        "\n",
        "# Preprocess the UDS dataset\n",
        "uds_df['NACCUDSD'] = uds_df['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0)\n",
        "uds_features = uds_df.drop(columns=['NACCUDSD'])\n",
        "uds_labels = uds_df['NACCUDSD'].values\n",
        "uds_features = uds_features.apply(pd.to_numeric, errors='coerce')\n",
        "uds_features.fillna(0, inplace=True)\n",
        "scaler_uds = StandardScaler()\n",
        "scaled_uds_features = scaler_uds.fit_transform(uds_features.values)\n",
        "uds_adj_matrix = np.eye(scaled_uds_features.shape[1])\n",
        "\n",
        "# Preprocess the MRI dataset\n",
        "vol_columns = [col for col in mriscanclean.columns if 'GVOL' in col]\n",
        "thick_columns = [col for col in mriscanclean.columns if 'AVGTH' in col]\n",
        "scaler_vol = StandardScaler()\n",
        "scaler_thick = StandardScaler()\n",
        "mriscanclean[vol_columns] = scaler_vol.fit_transform(mriscanclean[vol_columns])\n",
        "mriscanclean[thick_columns] = scaler_thick.fit_transform(mriscanclean[thick_columns])\n",
        "num_patients = mriscanclean.shape[0]\n",
        "num_nodes = 62\n",
        "num_features = 2\n",
        "mri_patient_features = np.zeros((num_patients, num_nodes, num_features))\n",
        "for i in range(num_patients):\n",
        "    mri_patient_features[i, :, 0] = mriscanclean.iloc[i][vol_columns].values\n",
        "    mri_patient_features[i, :, 1] = mriscanclean.iloc[i][thick_columns].values\n",
        "mri_labels = mriscanclean['NACCUDSD'].apply(lambda x: 1 if x in [2, 3, 4] else 0).values\n",
        "mri_adj_matrix = pd.read_csv('combined_adjacency_matrix.csv', index_col=0, header=0).values\n",
        "\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 64)\n",
        "        self.conv2 = GCNConv(64, 32)\n",
        "        self.conv3 = GCNConv(32, 16)\n",
        "        self.conv4 = GCNConv(16, 8)\n",
        "        self.fc = torch.nn.Linear(8, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv4(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "class BrainDataset(Dataset):\n",
        "    def __init__(self, patient_features, adjacency_matrix, labels):\n",
        "        self.patient_features = patient_features\n",
        "        self.adjacency_matrix = adjacency_matrix\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patient_features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = torch.tensor(self.patient_features[idx], dtype=torch.float)\n",
        "        edge_index = torch.tensor(np.array(np.nonzero(self.adjacency_matrix)), dtype=torch.long)\n",
        "        y = torch.tensor(self.labels[idx], dtype=torch.float)\n",
        "        return Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "# Perform 5-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "combined_accuracies = []\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for train_index, test_index in kf.split(uds_labels):\n",
        "    # Prepare UDS data\n",
        "    uds_train_features, uds_test_features = scaled_uds_features[train_index], scaled_uds_features[test_index]\n",
        "    uds_train_labels, uds_test_labels = uds_labels[train_index], uds_labels[test_index]\n",
        "    uds_train_data_list = [Data(x=torch.tensor(uds_train_features[i].reshape(-1, 1), dtype=torch.float),\n",
        "                                edge_index=torch.tensor(np.array(np.nonzero(uds_adj_matrix)), dtype=torch.long),\n",
        "                                y=torch.tensor([uds_train_labels[i]], dtype=torch.float)) for i in range(len(uds_train_labels))]\n",
        "    uds_test_data_list = [Data(x=torch.tensor(uds_test_features[i].reshape(-1, 1), dtype=torch.float),\n",
        "                               edge_index=torch.tensor(np.array(np.nonzero(uds_adj_matrix)), dtype=torch.long),\n",
        "                               y=torch.tensor([uds_test_labels[i]], dtype=torch.float)) for i in range(len(uds_test_labels))]\n",
        "    uds_train_loader = DataLoader(uds_train_data_list, batch_size=20, shuffle=True)\n",
        "    uds_test_loader = DataLoader(uds_test_data_list, batch_size=20, shuffle=False)\n",
        "\n",
        "    # Prepare MRI data\n",
        "    mri_train_features, mri_test_features = mri_patient_features[train_index], mri_patient_features[test_index]\n",
        "    mri_train_labels, mri_test_labels = mri_labels[train_index], mri_labels[test_index]\n",
        "    mri_train_dataset = BrainDataset(mri_train_features, mri_adj_matrix, mri_train_labels)\n",
        "    mri_test_dataset = BrainDataset(mri_test_features, mri_adj_matrix, mri_test_labels)\n",
        "    mri_train_loader = DataLoader(mri_train_dataset, batch_size=20, shuffle=True)\n",
        "    mri_test_loader = DataLoader(mri_test_dataset, batch_size=20, shuffle=False)\n",
        "\n",
        "    # Train UDS GNN\n",
        "    uds_model = GNN(in_channels=1).to(device)\n",
        "    optimizer = torch.optim.Adam(uds_model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    uds_model.train()\n",
        "    for epoch in range(10):\n",
        "        for data in uds_train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = uds_model(data)\n",
        "            loss = criterion(out, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Train MRI GNN\n",
        "    mri_model = GNN(in_channels=2).to(device)\n",
        "    optimizer = torch.optim.Adam(mri_model.parameters(), lr=0.01)\n",
        "    criterion = torch.nn.BCELoss()\n",
        "    mri_model.train()\n",
        "    for epoch in range(20):\n",
        "        for data in mri_train_loader:\n",
        "            data = data.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = mri_model(data)\n",
        "            loss = criterion(out, data.y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Get predictions for UDS and MRI\n",
        "    uds_model.eval()\n",
        "    mri_model.eval()\n",
        "    uds_preds = []\n",
        "    mri_preds = []\n",
        "    with torch.no_grad():\n",
        "        for data in uds_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = uds_model(data)\n",
        "            uds_preds.extend(out.cpu().numpy())\n",
        "\n",
        "        for data in mri_test_loader:\n",
        "            data = data.to(device)\n",
        "            out = mri_model(data)\n",
        "            mri_preds.extend(out.cpu().numpy())\n",
        "\n",
        "    uds_preds = np.array(uds_preds).flatten()\n",
        "    mri_preds = np.array(mri_preds).flatten()\n",
        "\n",
        "    # Weigh UDS predictions higher\n",
        "    combined_preds = (uds_preds * 0.7) + (mri_preds * 0.3)\n",
        "    combined_preds_binary = (combined_preds > 0.5).astype(int)\n",
        "    combined_accuracy = accuracy_score(uds_test_labels, combined_preds_binary)\n",
        "    combined_accuracies.append(combined_accuracy)\n",
        "    print(f'Fold Test Accuracy: {combined_accuracy:.4f}')\n",
        "\n",
        "# Print combined 5-fold cross-validation accuracy\n",
        "mean_combined_accuracy = np.mean(combined_accuracies)\n",
        "std_combined_accuracy = np.std(combined_accuracies)\n",
        "print(f'Combined 5-Fold Cross-Validation Accuracy: {mean_combined_accuracy:.4f} ± {std_combined_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "1Tywlf_e3SRI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}